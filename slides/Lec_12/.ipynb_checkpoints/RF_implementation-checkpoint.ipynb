{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "040eb77d",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "096b9942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import cartopy\n",
    "import cartopy.crs as crs\n",
    "import cartopy.feature as cfeature\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "from scipy.stats import skew, kurtosis\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "import scipy\n",
    "import pymannkendall as mk\n",
    "import networkx\n",
    "import decorator\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "%matplotlib inline\n",
    "plt.rcParams.update(plt.rcParamsDefault)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15162b0b",
   "metadata": {},
   "source": [
    "### RF models (one for each site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1befeb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train Random Forest models at each individual site using 75% of the data and test using the remaining 25%\n",
    "### This code block outputs two dataframes:\n",
    "### (1) RF_results; this dataframe lists different metrics for the performance of RF at each site, and also it lists\n",
    "### the top three features in order of importance\n",
    "### (2) RF_allfeatures; this dataframe contains the relative importance values for each of the 16 predictors used \n",
    "### in the model for each site; size of RF_allfeatures = (# of sites * 16) = (259 * 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba404fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('*/RF_single_data/') #replace * with your local directory where you saved the folder 'RF_single_data'\n",
    "sites = glob.glob('*.csv')\n",
    "from scipy.stats import rankdata\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.read_csv(sites[0])\n",
    "df = df.drop(columns = ['datetime', 'NSC'])\n",
    "feature_list = list(df.columns)\n",
    "\n",
    "# pre-allocate a dataframe\n",
    "RF_results = pd.DataFrame(index= list(range(len(sites))), columns= ['siteid', 'n', 'mae', 'rmse', 'accuracy', 'NSE',\n",
    "                                                                    '1st_feature', '2nd_feature', '3rd_feature',\n",
    "                                                                   '1st_importnace', '2nd_importnace', '3rd_importance'])\n",
    "\n",
    "RF_allfeatures = pd.DataFrame(index= list(range(len(sites))), columns= feature_list[:-1])\n",
    "\n",
    "for s in range(len(sites)):\n",
    "    \n",
    "    df = pd.read_csv(sites[s])\n",
    "    df = df.drop(columns = [df.columns[0], 'NSC'])\n",
    "    df = df.dropna()\n",
    "    \n",
    "    RF_results['siteid'].iloc[s] = sites[s][:-4]\n",
    "    RF_results['n'].iloc[s] = df.shape[0]\n",
    "    \n",
    "    \n",
    "    # Labels are the values we want to predict\n",
    "    labels = np.array(df['SC_mean'])\n",
    "    # Remove the labels from the features\n",
    "    features= df.drop('SC_mean', axis = 1)\n",
    "    std_scaler = StandardScaler()\n",
    "    features = std_scaler.fit_transform(features.to_numpy())\n",
    "    # Saving feature names for later use\n",
    "    feature_list = list(df.columns)\n",
    "    # Convert to numpy array\n",
    "    #features = np.array(features)\n",
    "    \n",
    "    # Using Skicit-learn to split data into training and testing sets\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    # Split the data into training and testing sets\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.25, random_state = 42)\n",
    "    # Import the model we are using\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    # Instantiate model with 1000 decision trees\n",
    "    rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "    # Train the model on training data\n",
    "    rf.fit(train_features, train_labels);\n",
    "    \n",
    "    \n",
    "    ## Model Performance ##\n",
    "\n",
    "    predictions = rf.predict(test_features) # Use the forest's predict method on the test data\n",
    "    # Calculate mae, rmse and accuracy\n",
    "    RF_results['mae'][s] = round(np.mean(abs(predictions - test_labels)), 2)\n",
    "    RF_results['rmse'][s] = round(np.sqrt(np.mean(np.power( (predictions - test_labels), 2))), 2)\n",
    "    mape = 100 * (abs(predictions - test_labels)/ test_labels) # Calculate mean absolute percentage error (MAPE)\n",
    "    RF_results['accuracy'][s] = round((100 - np.nanmean(mape)), 2)\n",
    "    RF_results['NSE'][s] = 1 - (np.sum(np.power( (predictions - test_labels), 2)) / np.sum(np.power( (np.nanmean(test_labels) - test_labels), 2)))\n",
    "    \n",
    "    \n",
    "    # Feature Importnace ##\n",
    "    importances = list(rf.feature_importances_)\n",
    "    \n",
    "    RF_allfeatures.iloc[s,:] = importances\n",
    "\n",
    "    rank = (len(importances) - rankdata(importances)).astype(int)\n",
    "    importances_ranked = [x for _, x in sorted(zip(rank, importances))]\n",
    "    features_ranked = [x for _, x in sorted(zip(rank, feature_list))]\n",
    "\n",
    "    RF_results.iloc[s,6:9] = features_ranked[0:3]\n",
    "    RF_results.iloc[s,9:12] = importances_ranked[0:3]\n",
    "    \n",
    "    print(s)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40996ba",
   "metadata": {},
   "source": [
    "#### Plot results of feature importance (averaged for each climate zone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09417166",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata= pd.read_csv('*/metadata.csv') #replace * with your local directory where you saved the folder 'metadata'\n",
    "metadata['DI'] = metadata['PET'].to_numpy()/(metadata['PPTAVG_BASIN'].to_numpy()*10)\n",
    "metadata['aridity'] = 'NAN'\n",
    "metadata['aridity'][metadata['DI'] < 0.7] = 'wet'\n",
    "metadata['aridity'][(metadata['DI'] >= 0.7) & (metadata['DI'] < 1.2)] = 'temperate'\n",
    "metadata['aridity'][metadata['DI'] > 1.2] = 'arid'\n",
    "\n",
    "RF_allfeatures['siteid']= np.nan\n",
    "RF_allfeatures['aridity']= np.nan\n",
    "RF_allfeatures['siteid'] = metadata['siteid']\n",
    "RF_allfeatures['aridity'] = metadata['aridity']\n",
    "\n",
    "RF_allfeatures = pd.melt(RF_allfeatures, id_vars=['siteid', 'aridity'])\n",
    "\n",
    "plt.figure(figsize=(10,7), dpi= 300)\n",
    "\n",
    "palette ={\"wet\": \"blue\", \"temperate\": \"green\", \"arid\": \"red\"}\n",
    "ax = sns.barplot(x=\"value\", y=\"variable\", hue=\"aridity\", data=RF_allfeatures, palette= palette, errcolor= 'black')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da81fee7",
   "metadata": {},
   "source": [
    "### RF models (one for each climate zone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f2bb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Similar to RF-models in the previous section, this code block returns two dataframes: (RF_results & RF_allfeatures)\n",
    "### However, unlike the previous code block, here we perform a randomized search for hyperparameter tuning\n",
    "### This is provided here as an example, and similar implementation can be carried out for the previous code block\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e98fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import rankdata\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "os.chdir('*/RF_regional_data') #replace * with your local directory where you saved the folder 'RF_single_data'\n",
    "data_files = glob.glob('*.csv')\n",
    "\n",
    "df = pd.read_csv(data_files[0])\n",
    "df = df.drop(columns = ['datetime'])\n",
    "feature_list = list(df.columns)\n",
    "\n",
    "# pre-allocate a dataframe\n",
    "RF_results = pd.DataFrame(index= list(range(len(data_files))), columns= ['n', 'mae', 'rmse', 'accuracy', 'NSE',\n",
    "                        '1st_feature', '2nd_feature', '3rd_feature','1st_importnace', '2nd_importnace', \n",
    "                                                                    '3rd_importance'])\n",
    "\n",
    "RF_allfeatures = pd.DataFrame(index= list(range(len(data_files))), columns= feature_list[:-1])\n",
    "  \n",
    "for i in range(len(data_files)):\n",
    "    \n",
    "    df = pd.read_csv(data_files[i])\n",
    "    df = df.drop(columns = [df.columns[0], 'datetime'])\n",
    "    df = df.dropna()\n",
    "\n",
    "    RF_results['n'][i] = df.shape[0]\n",
    "    \n",
    "    labels = np.array(df['SC_mean'])\n",
    "    features= df.drop('SC_mean', axis = 1) # Remove the labels from the features\n",
    "    feature_list = list(df.columns) # Saving feature names for later use\n",
    "    features = np.array(features) # Convert to numpy array\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(features, \n",
    "                                                    labels, test_size = 0.25, random_state = 42)\n",
    "\n",
    "    \n",
    "    # Randomized search\n",
    "    # Number of trees in random forest\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "\n",
    "    # Number of features to consider at every split\n",
    "    max_features = ['auto', 'sqrt']\n",
    "\n",
    "    # Maximum number of levels in tree\n",
    "    max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "    max_depth.append(None)\n",
    "\n",
    "    # Minimum number of samples required to split a node\n",
    "    min_samples_split = [2, 5, 10]\n",
    "    # Minimum number of samples required at each leaf node\n",
    "    min_samples_leaf = [1, 2, 4]\n",
    "    # Method of selecting samples for training each tree\n",
    "    bootstrap = [True, False]\n",
    "    # Create the random grid\n",
    "    random_grid = {'n_estimators': n_estimators,'max_features': max_features,\n",
    "               'max_depth': max_depth,'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,'bootstrap': bootstrap}\n",
    "    \n",
    "    rf = RandomForestRegressor()\n",
    "    \n",
    "    rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, \n",
    "                                   n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "    \n",
    "    rf_random.fit(train_features, train_labels)\n",
    "    \n",
    "    print(rf_random.best_params_)\n",
    "    best_random = rf_random.best_estimator_\n",
    "    \n",
    "    \n",
    "    ## Model Performance ##\n",
    "\n",
    "    predictions = best_random.predict(test_features) # Use the forest's predict method on the test data\n",
    "    # Calculate mae, rmse and accuracy\n",
    "    RF_results['mae'][i] = round(np.mean(abs(predictions - test_labels)), 2)\n",
    "    RF_results['rmse'][i] = round(np.sqrt(np.mean(np.power( (predictions - test_labels), 2))), 2)\n",
    "    mape = 100 * (abs(predictions - test_labels)/ test_labels) # Calculate mean absolute percentage error (MAPE)\n",
    "    RF_results['accuracy'][i] = round((100 - np.nanmean(mape)), 2)\n",
    "    RF_results['NSE'][i] = 1 - (np.sum(np.power( (predictions - test_labels), 2)) / np.sum(np.power( (np.nanmean(test_labels) - test_labels), 2)))\n",
    "    \n",
    "    \n",
    "    # Feature Importnace ##\n",
    "    importances = list(best_random.feature_importances_)\n",
    "    \n",
    "    RF_allfeatures.iloc[i,:] = importances\n",
    "\n",
    "    rank = (len(importances) - rankdata(importances)).astype(int)\n",
    "    importances_ranked = [x for _, x in sorted(zip(rank, importances))]\n",
    "    features_ranked = [x for _, x in sorted(zip(rank, feature_list))]\n",
    "\n",
    "    RF_results.iloc[i,5:8] = features_ranked[0:3]\n",
    "    RF_results.iloc[i,8:11] = importances_ranked[0:3]\n",
    "    \n",
    "    print(i)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
